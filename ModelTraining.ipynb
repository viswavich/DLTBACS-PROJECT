{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAic1ApE4iL6BNmUBY8XiI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/viswavich/DLTBACS-PROJECT/blob/main/ModelTraining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset\n",
        "file_path = '/train.csv'\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Display first few rows\n",
        "print(data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "q38slrmgj3jY",
        "outputId": "394b6a54-2d2d-41d2-a106-7f5852fe81bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   ACTION  RESOURCE  MGR_ID  ROLE_ROLLUP_1  ROLE_ROLLUP_2  ROLE_DEPTNAME  \\\n",
            "0       1     39353   85475         117961         118300         123472   \n",
            "1       1     17183    1540         117961         118343         123125   \n",
            "2       1     36724   14457         118219         118220         117884   \n",
            "3       1     36135    5396         117961         118343         119993   \n",
            "4       1     42680    5905         117929         117930         119569   \n",
            "\n",
            "   ROLE_TITLE  ROLE_FAMILY_DESC  ROLE_FAMILY  ROLE_CODE  \n",
            "0      117905            117906       290919     117908  \n",
            "1      118536            118536       308574     118539  \n",
            "2      117879            267952        19721     117880  \n",
            "3      118321            240983       290919     118322  \n",
            "4      119323            123932        19793     119325  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "UzTftMaylqXd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Features (X) and Label (y)\n",
        "X = data.drop('ACTION', axis=1)  # Drop ACTION from features\n",
        "y = data['ACTION']               # Label = ACTION (1 = Grant, 0 = Deny)"
      ],
      "metadata": {
        "id": "x_0wEvpclss5"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "print(\"Training data shape:\", X_train.shape)\n",
        "print(\"Testing data shape:\", X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "_qtqlrQxlyGw",
        "outputId": "de3e8109-3b2a-474d-f35b-e5dc2dacd379"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (26215, 8)\n",
            "Testing data shape: (6554, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import TensorFlow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "# Build the model\n",
        "model = Sequential()\n",
        "\n",
        "# Input layer + Hidden layer\n",
        "model.add(Dense(32, activation='relu', input_shape=(X_train.shape[1],)))  # 32 neurons, ReLU activation\n",
        "\n",
        "# Another hidden layer\n",
        "model.add(Dense(16, activation='relu'))  # 16 neurons\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))  # Sigmoid because output is binary (0 or 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PIvpOa6jl3ry",
        "outputId": "a567bd67-4755-4c44-f051-80c6a9fd13f8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',               # Adam optimizer (fast and good for small datasets)\n",
        "    loss='binary_crossentropy',      # Loss for binary classification\n",
        "    metrics=['accuracy']             # Track accuracy during training\n",
        ")"
      ],
      "metadata": {
        "id": "NSlSeurhmMVV"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "history = model.fit(\n",
        "    X_train, y_train,\n",
        "    epochs=50,           # Number of passes over the entire dataset\n",
        "    batch_size=32,       # Number of samples processed before model update\n",
        "    validation_split=0.2,  # 20% of training data used for validation\n",
        "    verbose=1            # Show training progress\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3kFIKXLxmOU8",
        "outputId": "2e9f3b46-f7a9-44a1-c391-099167758d50"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8824 - loss: 547.0091 - val_accuracy: 0.9416 - val_loss: 223.2790\n",
            "Epoch 2/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8870 - loss: 211.8909 - val_accuracy: 0.9329 - val_loss: 147.9048\n",
            "Epoch 3/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8948 - loss: 173.9030 - val_accuracy: 0.9352 - val_loss: 140.6109\n",
            "Epoch 4/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9009 - loss: 138.3518 - val_accuracy: 0.3036 - val_loss: 335.3306\n",
            "Epoch 5/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8895 - loss: 155.0395 - val_accuracy: 0.9395 - val_loss: 113.4287\n",
            "Epoch 6/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8959 - loss: 122.9796 - val_accuracy: 0.4742 - val_loss: 174.9716\n",
            "Epoch 7/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8934 - loss: 113.4943 - val_accuracy: 0.5508 - val_loss: 98.3508\n",
            "Epoch 8/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8858 - loss: 90.2272 - val_accuracy: 0.9424 - val_loss: 93.6553\n",
            "Epoch 9/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8900 - loss: 105.3558 - val_accuracy: 0.9014 - val_loss: 98.8429\n",
            "Epoch 10/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8910 - loss: 76.9415 - val_accuracy: 0.9449 - val_loss: 78.8927\n",
            "Epoch 11/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8897 - loss: 76.5288 - val_accuracy: 0.9449 - val_loss: 77.7286\n",
            "Epoch 12/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8902 - loss: 70.9903 - val_accuracy: 0.7826 - val_loss: 33.1496\n",
            "Epoch 13/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8954 - loss: 47.8927 - val_accuracy: 0.9456 - val_loss: 136.3417\n",
            "Epoch 14/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8893 - loss: 55.3443 - val_accuracy: 0.9367 - val_loss: 29.2514\n",
            "Epoch 15/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8884 - loss: 44.6711 - val_accuracy: 0.9456 - val_loss: 111.8576\n",
            "Epoch 16/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8932 - loss: 47.0128 - val_accuracy: 0.9447 - val_loss: 47.3498\n",
            "Epoch 17/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8914 - loss: 28.7671 - val_accuracy: 0.9451 - val_loss: 55.0616\n",
            "Epoch 18/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8926 - loss: 35.1682 - val_accuracy: 0.7322 - val_loss: 31.0989\n",
            "Epoch 19/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8833 - loss: 27.1283 - val_accuracy: 0.9449 - val_loss: 28.4225\n",
            "Epoch 20/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8942 - loss: 24.9666 - val_accuracy: 0.9455 - val_loss: 51.2738\n",
            "Epoch 21/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8943 - loss: 21.1064 - val_accuracy: 0.4335 - val_loss: 31.7913\n",
            "Epoch 22/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8893 - loss: 18.3720 - val_accuracy: 0.9422 - val_loss: 11.4659\n",
            "Epoch 23/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8881 - loss: 15.2554 - val_accuracy: 0.9432 - val_loss: 13.5299\n",
            "Epoch 24/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8901 - loss: 8.9417 - val_accuracy: 0.9146 - val_loss: 6.0357\n",
            "Epoch 25/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8914 - loss: 5.8839 - val_accuracy: 0.9332 - val_loss: 3.7238\n",
            "Epoch 26/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8938 - loss: 4.6189 - val_accuracy: 0.9388 - val_loss: 3.0474\n",
            "Epoch 27/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 2.0927 - val_accuracy: 0.9447 - val_loss: 2.7169\n",
            "Epoch 28/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9218 - loss: 1.2981 - val_accuracy: 0.9455 - val_loss: 2.9018\n",
            "Epoch 29/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 1.0771 - val_accuracy: 0.9456 - val_loss: 2.2642\n",
            "Epoch 30/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9302 - loss: 0.6625 - val_accuracy: 0.9456 - val_loss: 1.6758\n",
            "Epoch 31/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9369 - loss: 0.2903 - val_accuracy: 0.9456 - val_loss: 1.7474\n",
            "Epoch 32/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9386 - loss: 0.3149 - val_accuracy: 0.9453 - val_loss: 1.6825\n",
            "Epoch 33/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9414 - loss: 0.3499 - val_accuracy: 0.9456 - val_loss: 1.7236\n",
            "Epoch 34/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9400 - loss: 0.2531 - val_accuracy: 0.9456 - val_loss: 1.6384\n",
            "Epoch 35/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9387 - loss: 0.2567 - val_accuracy: 0.9434 - val_loss: 1.6812\n",
            "Epoch 36/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9400 - loss: 0.2858 - val_accuracy: 0.9456 - val_loss: 1.7058\n",
            "Epoch 37/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9397 - loss: 0.2566 - val_accuracy: 0.9456 - val_loss: 1.5983\n",
            "Epoch 38/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9392 - loss: 0.2289 - val_accuracy: 0.9456 - val_loss: 1.5981\n",
            "Epoch 39/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9417 - loss: 0.2219 - val_accuracy: 0.9456 - val_loss: 1.5979\n",
            "Epoch 40/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9406 - loss: 0.2250 - val_accuracy: 0.9456 - val_loss: 1.5731\n",
            "Epoch 41/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9400 - loss: 0.2268 - val_accuracy: 0.9456 - val_loss: 1.5788\n",
            "Epoch 42/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9417 - loss: 0.2220 - val_accuracy: 0.9456 - val_loss: 1.5762\n",
            "Epoch 43/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9411 - loss: 0.2238 - val_accuracy: 0.9456 - val_loss: 1.5751\n",
            "Epoch 44/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9413 - loss: 0.2231 - val_accuracy: 0.9456 - val_loss: 1.5740\n",
            "Epoch 45/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9413 - loss: 0.2232 - val_accuracy: 0.9456 - val_loss: 1.5766\n",
            "Epoch 46/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9389 - loss: 0.2298 - val_accuracy: 0.9456 - val_loss: 1.5764\n",
            "Epoch 47/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9402 - loss: 0.2262 - val_accuracy: 0.9456 - val_loss: 1.5766\n",
            "Epoch 48/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9388 - loss: 0.2301 - val_accuracy: 0.9456 - val_loss: 1.5839\n",
            "Epoch 49/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9406 - loss: 0.2251 - val_accuracy: 0.9456 - val_loss: 1.5769\n",
            "Epoch 50/50\n",
            "\u001b[1m656/656\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9410 - loss: 0.2240 - val_accuracy: 0.9456 - val_loss: 1.5661\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on Test Set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "PP_rlrbmmj4r",
        "outputId": "b8aa7a7a-84c8-4fc9-bf6b-604e95e7999a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.9386 - loss: 0.6065\n",
            "Test Accuracy: 94.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make a prediction on a new request\n",
        "sample_input = X_test.iloc[0].values.reshape(1, -1)\n",
        "prediction = model.predict(sample_input)\n",
        "\n",
        "# Interpret result\n",
        "if prediction >= 0.5:\n",
        "    print(\"Access Granted ✅\")\n",
        "else:\n",
        "    print(\"Access Denied ❌\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "l4AMlliNmrdY",
        "outputId": "eb9aedbe-f5d4-45ae-ed60-886ed3bf88a9"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step\n",
            "Access Granted ✅\n"
          ]
        }
      ]
    }
  ]
}